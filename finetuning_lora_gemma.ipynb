{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets\n!pip install transformers\n!pip install peft\n!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:39:07.871556Z","iopub.execute_input":"2024-11-20T17:39:07.872524Z","iopub.status.idle":"2024-11-20T17:39:40.567149Z","shell.execute_reply.started":"2024-11-20T17:39:07.872475Z","shell.execute_reply":"2024-11-20T17:39:40.566019Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.34.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, Dataset\n\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer)\n\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport evaluate\nimport torch\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:39:40.568962Z","iopub.execute_input":"2024-11-20T17:39:40.569265Z","iopub.status.idle":"2024-11-20T17:39:47.645767Z","shell.execute_reply.started":"2024-11-20T17:39:40.569236Z","shell.execute_reply":"2024-11-20T17:39:47.645052Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# sst2\n# The Stanford Sentiment Treebank consists of sentences from movie reviews and human annotations of their sentiment. The task is to predict the sentiment of a given sentence. It uses the two-way (positive/negative) class split, with only sentence-level labels.\ndataset = load_dataset(\"sst2\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:40:19.371207Z","iopub.execute_input":"2024-11-20T17:40:19.371947Z","iopub.status.idle":"2024-11-20T17:40:23.388744Z","shell.execute_reply.started":"2024-11-20T17:40:19.371907Z","shell.execute_reply":"2024-11-20T17:40:23.387767Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 1821\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# display % of training data with label=1\nnp.array(dataset['train']['label']).sum()/len(dataset['train']['label'])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:40:26.328475Z","iopub.execute_input":"2024-11-20T17:40:26.329294Z","iopub.status.idle":"2024-11-20T17:40:26.383469Z","shell.execute_reply.started":"2024-11-20T17:40:26.329256Z","shell.execute_reply":"2024-11-20T17:40:26.382539Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0.5578256544269403"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\n\n# Reduce the training dataset to 8000 samples\ndataset[\"train\"] = dataset[\"train\"].select(range(8000))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:40:27.472079Z","iopub.execute_input":"2024-11-20T17:40:27.472980Z","iopub.status.idle":"2024-11-20T17:40:27.479898Z","shell.execute_reply.started":"2024-11-20T17:40:27.472946Z","shell.execute_reply":"2024-11-20T17:40:27.479036Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:40:29.478427Z","iopub.execute_input":"2024-11-20T17:40:29.478777Z","iopub.status.idle":"2024-11-20T17:40:29.484415Z","shell.execute_reply.started":"2024-11-20T17:40:29.478744Z","shell.execute_reply":"2024-11-20T17:40:29.483517Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 8000\n    })\n    validation: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['idx', 'sentence', 'label'],\n        num_rows: 1821\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:42:31.664202Z","iopub.execute_input":"2024-11-20T17:42:31.664574Z","iopub.status.idle":"2024-11-20T17:42:31.684604Z","shell.execute_reply.started":"2024-11-20T17:42:31.664543Z","shell.execute_reply":"2024-11-20T17:42:31.683719Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67ba9ed7a00e45e4949094d3f379a64b"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T17:42:46.476181Z","iopub.execute_input":"2024-11-20T17:42:46.476531Z","iopub.status.idle":"2024-11-20T17:42:54.614224Z","shell.execute_reply.started":"2024-11-20T17:42:46.476499Z","shell.execute_reply":"2024-11-20T17:42:54.613151Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T17:44:37.725104Z","iopub.execute_input":"2024-11-20T17:44:37.725495Z","iopub.status.idle":"2024-11-20T17:44:39.231322Z","shell.execute_reply.started":"2024-11-20T17:44:37.725462Z","shell.execute_reply":"2024-11-20T17:44:39.230388Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"model_checkpoint = 'google/gemma-2b-it'\n\n# define label maps\nid2label = {0: \"Negative\", 1: \"Positive\"}\nlabel2id = {\"Negative\":0, \"Positive\":1}\n\n# generate classification model from model_checkpoint\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:44:42.317667Z","iopub.execute_input":"2024-11-20T17:44:42.318032Z","iopub.status.idle":"2024-11-20T17:46:47.669208Z","shell.execute_reply.started":"2024-11-20T17:44:42.317998Z","shell.execute_reply":"2024-11-20T17:46:47.668323Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8abf177ab31a4cf9924d3f0a24e0059f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4e16493ccb043a48f92ccdbec73776e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"823b4916eb2843fab580166accc59f35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69bdc278ff20438c9cc57167b752fd5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9881509410ff4c88a88a7a30df9e8700"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3168639801dd4d9c962be1e10120f6b6"}},"metadata":{}},{"name":"stderr","text":"Some weights of GemmaForSequenceClassification were not initialized from the model checkpoint at google/gemma-2b-it and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# display architecture\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:46:54.266414Z","iopub.execute_input":"2024-11-20T17:46:54.267146Z","iopub.status.idle":"2024-11-20T17:46:54.273958Z","shell.execute_reply.started":"2024-11-20T17:46:54.267104Z","shell.execute_reply":"2024-11-20T17:46:54.273160Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"GemmaForSequenceClassification(\n  (model): GemmaModel(\n    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n    (layers): ModuleList(\n      (0-17): 18 x GemmaDecoderLayer(\n        (self_attn): GemmaSdpaAttention(\n          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): GemmaRotaryEmbedding()\n        )\n        (mlp): GemmaMLP(\n          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n          (act_fn): PytorchGELUTanh()\n        )\n        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n  )\n  (score): Linear(in_features=2048, out_features=2, bias=False)\n)"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# create tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n\n# add pad token if none exists\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:46:56.120074Z","iopub.execute_input":"2024-11-20T17:46:56.120464Z","iopub.status.idle":"2024-11-20T17:46:59.054474Z","shell.execute_reply.started":"2024-11-20T17:46:56.120429Z","shell.execute_reply":"2024-11-20T17:46:59.053479Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48acfb7a706d4f1fbcb3469ab22c478d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a195019051744cf8851e4a9c164b126e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd249f4dcabc4985a9974d44140d3769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b67f0e29464b1c8a8fcd5857e25a52"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# create tokenize function\ndef tokenize_function(examples):\n    # extract text\n    text = examples[\"sentence\"]\n\n    #tokenize and truncate text\n    tokenizer.truncation_side = \"left\"\n    tokenized_inputs = tokenizer(\n        text,\n        return_tensors=\"np\",\n        truncation=True,\n        max_length=512\n    )\n\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:01.592487Z","iopub.execute_input":"2024-11-20T17:47:01.592864Z","iopub.status.idle":"2024-11-20T17:47:01.597798Z","shell.execute_reply.started":"2024-11-20T17:47:01.592830Z","shell.execute_reply":"2024-11-20T17:47:01.596917Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# tokenize training and validation datasets\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:03.648444Z","iopub.execute_input":"2024-11-20T17:47:03.649399Z","iopub.status.idle":"2024-11-20T17:47:05.414067Z","shell.execute_reply.started":"2024-11-20T17:47:03.649356Z","shell.execute_reply":"2024-11-20T17:47:05.413216Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35f792056ae541cabcdf6ee04a2a9167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7daf4971c13e414385cb7092dd5178c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd5cf173783b4bc0997b469f6ac5b263"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 8000\n    })\n    validation: Dataset({\n        features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['idx', 'sentence', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 1821\n    })\n})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# create data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:07.038082Z","iopub.execute_input":"2024-11-20T17:47:07.038503Z","iopub.status.idle":"2024-11-20T17:47:07.042853Z","shell.execute_reply.started":"2024-11-20T17:47:07.038468Z","shell.execute_reply":"2024-11-20T17:47:07.041921Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# import accuracy evaluation metric\naccuracy = evaluate.load(\"accuracy\")\n\nf1 = evaluate.load(\"f1\")\nprecision = evaluate.load(\"precision\")\nrecall = evaluate.load(\"recall\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    acc = accuracy.compute(predictions=predictions, references=labels)\n    f1_score = f1.compute(predictions=predictions, references=labels, average='weighted')\n    prec = precision.compute(predictions=predictions, references=labels, average='weighted')\n    rec = recall.compute(predictions=predictions, references=labels, average='weighted')\n    return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"], \"precision\": prec[\"precision\"], \"recall\": rec[\"recall\"]}","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:08.150239Z","iopub.execute_input":"2024-11-20T17:47:08.150603Z","iopub.status.idle":"2024-11-20T17:47:10.969948Z","shell.execute_reply.started":"2024-11-20T17:47:08.150572Z","shell.execute_reply":"2024-11-20T17:47:10.969063Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92612666c3245ab9e24c88b4bfe0ebe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cebb1ea40cb6466a9a60e635ecee3634"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1cb2aa6a080464aab7b47f2f7cd307d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"957aadbe19c842e0ba591fc3c126ba1d"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# define list of examples\ntext_list = [\"a feel-good picture in the best sense of the term .\", \"resourceful and ingenious entertainment .\", \"it 's just incredibly dull .\", \"the movie 's biggest offense is its complete and utter lack of tension .\",\n             \"impresses you with its open-endedness and surprises .\", \"unless you are in dire need of a diesel fix , there is no real reason to see it .\"]\n\nprint(\"Untrained model predictions:\")\nprint(\"----------------------------\")\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n    # compute logits\n    logits = model(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n\n    print(text + \" - \" + id2label[predictions.tolist()])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:12.593416Z","iopub.execute_input":"2024-11-20T17:47:12.594356Z","iopub.status.idle":"2024-11-20T17:47:21.136185Z","shell.execute_reply.started":"2024-11-20T17:47:12.594315Z","shell.execute_reply":"2024-11-20T17:47:21.135246Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Untrained model predictions:\n----------------------------\na feel-good picture in the best sense of the term . - Positive\nresourceful and ingenious entertainment . - Negative\nit 's just incredibly dull . - Negative\nthe movie 's biggest offense is its complete and utter lack of tension . - Negative\nimpresses you with its open-endedness and surprises . - Negative\nunless you are in dire need of a diesel fix , there is no real reason to see it . - Negative\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"Untrained model metrics:\")\nprint(\"----------------------------\")\neval_pred = model.predict(tokenized_dataset['validation'])\nmetrics = compute_metrics(eval_pred)\nmetrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T17:47:25.990520Z","iopub.execute_input":"2024-11-20T17:47:25.991380Z","iopub.status.idle":"2024-11-20T17:47:26.287398Z","shell.execute_reply.started":"2024-11-20T17:47:25.991342Z","shell.execute_reply":"2024-11-20T17:47:26.286214Z"}},"outputs":[{"name":"stdout","text":"Untrained model metrics:\n----------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntrained model metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m eval_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(tokenized_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m compute_metrics(eval_pred)\n\u001b[1;32m      5\u001b[0m metrics\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'GemmaForSequenceClassification' object has no attribute 'predict'"],"ename":"AttributeError","evalue":"'GemmaForSequenceClassification' object has no attribute 'predict'","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"print(model.num_parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T17:47:46.823142Z","iopub.execute_input":"2024-11-20T17:47:46.823810Z","iopub.status.idle":"2024-11-20T17:47:46.829203Z","shell.execute_reply.started":"2024-11-20T17:47:46.823774Z","shell.execute_reply":"2024-11-20T17:47:46.828269Z"}},"outputs":[{"name":"stdout","text":"2506176512\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"peft_config = LoraConfig(\n       task_type=\"SEQ_CLS\",\n       r=4,\n       lora_alpha=32,\n       lora_dropout=0.01,\n       target_modules=['q_proj', 'k_proj', 'v_proj'], # Replace with the correct module names\n   )","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:48.242153Z","iopub.execute_input":"2024-11-20T17:47:48.242844Z","iopub.status.idle":"2024-11-20T17:47:48.247063Z","shell.execute_reply.started":"2024-11-20T17:47:48.242811Z","shell.execute_reply":"2024-11-20T17:47:48.246078Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"peft_config","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:49.583561Z","iopub.execute_input":"2024-11-20T17:47:49.584407Z","iopub.status.idle":"2024-11-20T17:47:49.589834Z","shell.execute_reply.started":"2024-11-20T17:47:49.584369Z","shell.execute_reply":"2024-11-20T17:47:49.588918Z"},"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'v_proj', 'k_proj', 'q_proj'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:47:50.659410Z","iopub.execute_input":"2024-11-20T17:47:50.659769Z","iopub.status.idle":"2024-11-20T17:47:50.733564Z","shell.execute_reply.started":"2024-11-20T17:47:50.659737Z","shell.execute_reply":"2024-11-20T17:47:50.732697Z"},"trusted":true},"outputs":[{"name":"stdout","text":"trainable params: 630,784 || all params: 2,506,807,296 || trainable%: 0.0252\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# hyperparameters\nlr = 1e-3\nbatch_size = 16\nnum_epochs = 3","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:48:11.122227Z","iopub.execute_input":"2024-11-20T17:48:11.122562Z","iopub.status.idle":"2024-11-20T17:48:11.126683Z","shell.execute_reply.started":"2024-11-20T17:48:11.122535Z","shell.execute_reply":"2024-11-20T17:48:11.125789Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# define training arguments\ntraining_args = TrainingArguments(\n    output_dir= model_checkpoint + \"-lora-text-classification\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:48:14.095603Z","iopub.execute_input":"2024-11-20T17:48:14.095961Z","iopub.status.idle":"2024-11-20T17:48:14.176362Z","shell.execute_reply.started":"2024-11-20T17:48:14.095928Z","shell.execute_reply":"2024-11-20T17:48:14.175449Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# creater trainer object\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:48:27.393859Z","iopub.execute_input":"2024-11-20T17:48:27.394787Z","iopub.status.idle":"2024-11-20T18:06:41.724365Z","shell.execute_reply.started":"2024-11-20T17:48:27.394745Z","shell.execute_reply":"2024-11-20T18:06:41.723171Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114317155554292, max=1.0â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ea9a40acd34d0dae6ae376dc41e2d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241120_174846-do1gelj1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/isha-team/huggingface/runs/do1gelj1' target=\"_blank\">google/gemma-2b-it-lora-text-classification</a></strong> to <a href='https://wandb.ai/isha-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/isha-team/huggingface' target=\"_blank\">https://wandb.ai/isha-team/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/isha-team/huggingface/runs/do1gelj1' target=\"_blank\">https://wandb.ai/isha-team/huggingface/runs/do1gelj1</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 17:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.722900</td>\n      <td>0.766808</td>\n      <td>0.545872</td>\n      <td>0.428186</td>\n      <td>0.701704</td>\n      <td>0.545872</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.572100</td>\n      <td>0.545272</td>\n      <td>0.725917</td>\n      <td>0.724504</td>\n      <td>0.732873</td>\n      <td>0.725917</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.449700</td>\n      <td>0.496390</td>\n      <td>0.759174</td>\n      <td>0.758980</td>\n      <td>0.759435</td>\n      <td>0.759174</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=0.5815789591471354, metrics={'train_runtime': 1090.5153, 'train_samples_per_second': 22.008, 'train_steps_per_second': 1.375, 'total_flos': 9621340605186048.0, 'train_loss': 0.5815789591471354, 'epoch': 3.0})"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"model.to('cpu')\n\nprint(\"Trained model predictions:\")\nprint(\"--------------------------\")\nfor text in text_list:\n    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cpu\")\n\n    logits = model(inputs).logits\n    predictions = torch.max(logits,1).indices\n\n    print(text + \" - \" + id2label[predictions.tolist()[0]])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:06:41.726581Z","iopub.execute_input":"2024-11-20T18:06:41.726950Z","iopub.status.idle":"2024-11-20T18:07:00.238893Z","shell.execute_reply.started":"2024-11-20T18:06:41.726908Z","shell.execute_reply":"2024-11-20T18:07:00.237993Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Trained model predictions:\n--------------------------\na feel-good picture in the best sense of the term . - Positive\nresourceful and ingenious entertainment . - Positive\nit 's just incredibly dull . - Negative\nthe movie 's biggest offense is its complete and utter lack of tension . - Positive\nimpresses you with its open-endedness and surprises . - Positive\nunless you are in dire need of a diesel fix , there is no real reason to see it . - Negative\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(model.num_parameters())","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:07:55.164137Z","iopub.execute_input":"2024-11-20T18:07:55.164531Z","iopub.status.idle":"2024-11-20T18:07:55.173249Z","shell.execute_reply.started":"2024-11-20T18:07:55.164494Z","shell.execute_reply":"2024-11-20T18:07:55.172233Z"},"trusted":true},"outputs":[{"name":"stdout","text":"2506807296\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"trainer.save_model(\"ishanarang/gemma2_finetune\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:07:57.960403Z","iopub.execute_input":"2024-11-20T18:07:57.961269Z","iopub.status.idle":"2024-11-20T18:07:58.745239Z","shell.execute_reply.started":"2024-11-20T18:07:57.961231Z","shell.execute_reply":"2024-11-20T18:07:58.744496Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:08:02.361964Z","iopub.execute_input":"2024-11-20T18:08:02.362716Z","iopub.status.idle":"2024-11-20T18:08:03.070902Z","shell.execute_reply.started":"2024-11-20T18:08:02.362681Z","shell.execute_reply":"2024-11-20T18:08:03.070157Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"model.push_to_hub(\"gemma2_finetune_sst2\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:08:45.732056Z","iopub.execute_input":"2024-11-20T18:08:45.732479Z","iopub.status.idle":"2024-11-20T18:08:48.241238Z","shell.execute_reply.started":"2024-11-20T18:08:45.732446Z","shell.execute_reply":"2024-11-20T18:08:48.240468Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/2.54M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118799402a8f46cc9b1e4fc5f26ea052"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ishanarang/gemma2_finetune_sst2/commit/dc59e34b2c568f5fb0f076293a22efa1f5590e7c', commit_message='Upload model', commit_description='', oid='dc59e34b2c568f5fb0f076293a22efa1f5590e7c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ishanarang/gemma2_finetune_sst2', endpoint='https://huggingface.co', repo_type='model', repo_id='ishanarang/gemma2_finetune_sst2'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}